{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfbff1a",
   "metadata": {},
   "source": [
    "# Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e12e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f156523",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSetPath='/edahome/msedalab/deyuan/HPWL_Estimation/ALIGN-Parser/Dataset/Data/'\n",
    "DataSetSize=373\n",
    "LargeNetThreshold=20000\n",
    "#Extreme_Case = []\n",
    "Extreme_Case = [265, 266, 267, 268, 269, 275, 276, 277, 278, 279] # Extreme Large Device Size Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea927324",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(torch.__version__)\n",
    "!python --version\n",
    "!nvcc --version\n",
    "#!cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d339d7",
   "metadata": {
    "id": "7991e79d"
   },
   "source": [
    "## Mean and Standard Deviation Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f0c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import csv\n",
    "\n",
    "available_design = [i for i in range(DataSetSize)]\n",
    "data_list = []\n",
    "device_features_list = []\n",
    "net_features_list = []\n",
    "\n",
    "\n",
    "prev_device_node_features = torch.Tensor()\n",
    "prev_net_node_features = torch.Tensor()\n",
    "\n",
    "for design_id in available_design:\n",
    "    \n",
    "    if design_id in Extreme_Case:\n",
    "        continue\n",
    "    \n",
    "    data = HeteroData()\n",
    "    \n",
    "    # Device Nodes\n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_device_nodes.csv'\n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        headers = next(rows)\n",
    "        device_node_features_data = np.asarray(list(rows), dtype=np.float32)\n",
    "        device_node_features_data = np.delete(device_node_features_data, 0, 1) # delete the id column\n",
    "        \n",
    "        device_node_features = torch.from_numpy(device_node_features_data)\n",
    "        data['device'].x = device_node_features\n",
    "        \n",
    "    \n",
    "    # Net Nodes\n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net_nodes.csv'\n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        headers = next(rows)\n",
    "        net_node_features_data = np.asarray(list(rows), dtype=np.float32)\n",
    "        net_node_features_data = np.delete(net_node_features_data, 0, 1) # delete the id column\n",
    "        \n",
    "        net_node_features = torch.from_numpy(net_node_features_data[:,:-1])\n",
    "        ground_truth = torch.from_numpy(net_node_features_data[:,-1])\n",
    "        data['net'].x = net_node_features\n",
    "        \n",
    "        data['net'].y = torch.log(ground_truth) # Log Value\n",
    "        \n",
    "        \n",
    "    # Gate to Net Edges Index\n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_gate2net_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        gate2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        gate2net_edge_index_data = torch.from_numpy(gate2net_edge_index_data)\n",
    "        gate2net_edge_index_data = gate2net_edge_index_data.to(torch.long)\n",
    "        N = gate2net_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['device', 'gate2net', 'net'].edge_index = gate2net_edge_index_data\n",
    "        else:\n",
    "            data['device', 'gate2net', 'net'].edge_index = torch.transpose(gate2net_edge_index_data, 0, 1)\n",
    "     \n",
    "    \n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2gate_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        net2gate_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        net2gate_edge_index_data = torch.from_numpy(net2gate_edge_index_data)\n",
    "        net2gate_edge_index_data = net2gate_edge_index_data.to(torch.long)\n",
    "        N = net2gate_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['net', 'net2gate', 'device'].edge_index = net2gate_edge_index_data\n",
    "        else:\n",
    "            data['net', 'net2gate', 'device'].edge_index = torch.transpose(net2gate_edge_index_data, 0, 1)\n",
    "        \n",
    "            \n",
    "    # Source to Net Edge Index\n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_source2net_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        source2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        source2net_edge_index_data = torch.from_numpy(source2net_edge_index_data)\n",
    "        source2net_edge_index_data = source2net_edge_index_data.to(torch.long)\n",
    "        N = source2net_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['device', 'source2net', 'net'].edge_index = source2net_edge_index_data\n",
    "        else:\n",
    "            data['device', 'source2net', 'net'].edge_index = torch.transpose(source2net_edge_index_data, 0, 1)\n",
    "     \n",
    "    \n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2source_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        net2source_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        net2source_edge_index_data = torch.from_numpy(net2source_edge_index_data)\n",
    "        net2source_edge_index_data = net2source_edge_index_data.to(torch.long)\n",
    "        N = net2source_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['net', 'net2source', 'device'].edge_index = net2source_edge_index_data\n",
    "        else:\n",
    "            data['net', 'net2source', 'device'].edge_index = torch.transpose(net2source_edge_index_data, 0, 1)\n",
    "        \n",
    "        \n",
    "    # Capacitor to Net Edge Index\n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_cap2net_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        cap2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        cap2net_edge_index_data = torch.from_numpy(cap2net_edge_index_data)\n",
    "        cap2net_edge_index_data = cap2net_edge_index_data.to(torch.long)\n",
    "        N = cap2net_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['device', 'cap2net', 'net'].edge_index = cap2net_edge_index_data\n",
    "        else:\n",
    "            data['device', 'cap2net', 'net'].edge_index = torch.transpose(cap2net_edge_index_data, 0, 1)\n",
    "     \n",
    "    \n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2cap_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        net2cap_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        net2cap_edge_index_data = torch.from_numpy(net2cap_edge_index_data)\n",
    "        net2cap_edge_index_data = net2cap_edge_index_data.to(torch.long)\n",
    "        N = net2cap_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['net', 'net2cap', 'device'].edge_index = net2cap_edge_index_data\n",
    "        else:\n",
    "            data['net', 'net2cap', 'device'].edge_index = torch.transpose(net2cap_edge_index_data, 0, 1)   \n",
    "      \n",
    "    \n",
    "    # Resistor to Net Edge Index\n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_res2net_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        res2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        res2net_edge_index_data = torch.from_numpy(res2net_edge_index_data)\n",
    "        res2net_edge_index_data = res2net_edge_index_data.to(torch.long)\n",
    "        N = res2net_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['device', 'res2net', 'net'].edge_index = res2net_edge_index_data\n",
    "        else:\n",
    "            data['device', 'res2net', 'net'].edge_index = torch.transpose(res2net_edge_index_data, 0, 1)\n",
    "     \n",
    "    \n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2res_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        net2res_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        net2res_edge_index_data = torch.from_numpy(net2res_edge_index_data)\n",
    "        net2res_edge_index_data = net2res_edge_index_data.to(torch.long)\n",
    "        N = net2res_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['net', 'net2res', 'device'].edge_index = net2res_edge_index_data\n",
    "        else:\n",
    "            data['net', 'net2res', 'device'].edge_index = torch.transpose(net2res_edge_index_data, 0, 1)   \n",
    "        \n",
    "    \n",
    "    # Net to Net Edge Index\n",
    "    path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2net_edges.csv'   \n",
    "    with open(path, newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter=',')\n",
    "        #next(rows)\n",
    "        net2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "        net2net_edge_index_data = torch.from_numpy(net2net_edge_index_data)\n",
    "        net2net_edge_index_data = net2net_edge_index_data.to(torch.long)\n",
    "        N = net2net_edge_index_data.shape[0]\n",
    "        if N == 0:\n",
    "            data['net', 'net2net', 'net'].edge_index = net2net_edge_index_data\n",
    "        else:\n",
    "            data['net', 'net2net', 'net'].edge_index = torch.transpose(net2net_edge_index_data, 0, 1)\n",
    "     \n",
    "\n",
    "    # Remove the Repeated Data\n",
    "    if(not torch.equal(device_node_features, prev_device_node_features)):\n",
    "        data_list.append(data)\n",
    "        device_features_list.append(device_node_features_data)\n",
    "        net_features_list.append(net_node_features_data)\n",
    "    prev_device_node_features = device_node_features\n",
    "\n",
    "\n",
    "device_features_list = [x for xs in device_features_list for x in xs]\n",
    "net_features_list = [x for xs in net_features_list for x in xs]\n",
    "device_features_list = np.array(device_features_list)\n",
    "net_features_list = np.array(net_features_list)\n",
    "\n",
    "\n",
    "print(\"Device Node Features' Shape: \" + str(device_features_list.shape))\n",
    "device_features_mean = np.mean(device_features_list, axis=0)\n",
    "device_features_std = np.std(device_features_list, axis=0)\n",
    "print(\"Device Node Features' Mean: \" + str(device_features_mean))\n",
    "print(\"Device Node Features' Std: \" + str(device_features_std))\n",
    "\n",
    "print(\"Net Node Features' Shape: \" + str(net_features_list.shape))\n",
    "net_features_mean = np.mean(net_features_list, axis=0)\n",
    "net_features_std = np.std(net_features_list, axis=0)\n",
    "print(\"Net Node Features' Mean: \" + str(net_features_mean))\n",
    "print(\"Net Node Features' Std: \" + str(net_features_std))\n",
    "\n",
    "print(\"DataSet size:\")\n",
    "print(len(data_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da624e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0a6434",
   "metadata": {},
   "source": [
    "# DataSet Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type = device_features_list[:,-1]\n",
    "print(\"Total Device: \" + str(len(device_type)))\n",
    "\n",
    "NumMos   = np.count_nonzero(device_type == 0)\n",
    "NumCap   = np.count_nonzero(device_type == 1)\n",
    "NumRes   = np.count_nonzero(device_type == 2)\n",
    "NumBlock = np.count_nonzero(device_type == 3)\n",
    "\n",
    "print(\"NumMos: \" + str(NumMos))\n",
    "print(\"NumCap: \" + str(NumCap))\n",
    "print(\"NumRes: \" + str(NumRes))\n",
    "print(\"NumBlock: \" + str(NumBlock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77697fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "wirelength = np.log(net_features_list[:,-1])\n",
    "#wirelength = net_features_list[:,-1]\n",
    "wirelength = np.sort(wirelength[net_features_list[:,1] == 0])\n",
    "num_wire = len(wirelength)\n",
    "print(\"Num wire: \" + str(num_wire))\n",
    "\n",
    "L_max = wirelength[(num_wire-1) - int(0.01*num_wire)]\n",
    "L_min = wirelength[0]\n",
    "interval = (L_max - L_min) / N\n",
    "print(\"L min:\" + str(L_min))\n",
    "print(\"L max:\" + str(wirelength[-1]))\n",
    "print(\"Interval: \" + str(interval))\n",
    "\n",
    "interval_list = []\n",
    "label = np.zeros(num_wire)\n",
    "\n",
    "for i in range(N+1):\n",
    "    interval_min = L_min + (i*interval)\n",
    "    interval_max = L_min + ((i+1)*interval)\n",
    "        \n",
    "    if (i == N):\n",
    "        label = np.where((wirelength >= interval_min), i, label)\n",
    "    else:\n",
    "        label = np.where((wirelength >= interval_min) & (wirelength < interval_max), i, label)  \n",
    "\n",
    "interval_num = np.zeros(N+1)\n",
    "   \n",
    "for i in range(N+1):\n",
    "    label_mask = np.where(label == i, True, False)\n",
    "    interval_num[i] = len(label[label_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [i for i in range(N+1)]\n",
    "\n",
    "x = np.arange(N+1)  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, interval_num, width, label='Real')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#ax.set_ylabel('num', fontsize=24)\n",
    "ax.set_title('Wirelength Distribution', fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "ax.set_xticks(x, labels, fontsize=8)\n",
    "ax.legend(loc='best', fontsize=24)\n",
    "\n",
    "\n",
    "fig.set_size_inches(16, 12)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "devicesize = device_features_list[:,0]\n",
    "devicesize = np.sort(devicesize)\n",
    "num_device = len(devicesize)\n",
    "print(\"Num device: \" + str(num_device))\n",
    "\n",
    "L_max = devicesize[(num_device-1) - int(0.01*num_device)]\n",
    "L_min = devicesize[0]\n",
    "interval = (L_max - L_min) / N\n",
    "print(\"L min:\" + str(L_min))\n",
    "print(\"L max:\" + str(devicesize[-1]))\n",
    "print(\"Interval: \" + str(interval))\n",
    "\n",
    "interval_list = []\n",
    "label = np.zeros(num_device)\n",
    "\n",
    "for i in range(N+1):\n",
    "    interval_min = L_min + (i*interval)\n",
    "    interval_max = L_min + ((i+1)*interval)\n",
    "        \n",
    "    if (i == N):\n",
    "        label = np.where((devicesize >= interval_min), i, label)\n",
    "    else:\n",
    "        label = np.where((devicesize >= interval_min) & (devicesize < interval_max), i, label)  \n",
    "\n",
    "interval_num = np.zeros(N+1)\n",
    "   \n",
    "for i in range(N+1):\n",
    "    label_mask = np.where(label == i, True, False)\n",
    "    interval_num[i] = len(label[label_mask])\n",
    "#print(interval_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a604b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [i for i in range(N+1)]\n",
    "\n",
    "x = np.arange(N+1)  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, interval_num, width, label='Real')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#ax.set_ylabel('num', fontsize=24)\n",
    "ax.set_title('Device Size Distribution', fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "ax.set_xticks(x, labels, fontsize=8)\n",
    "ax.legend(loc='best', fontsize=24)\n",
    "\n",
    "\n",
    "fig.set_size_inches(16, 12)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407e37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d948f64",
   "metadata": {},
   "source": [
    "# DataSet Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee65bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Dataset, Data\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "import random\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "class ALIGN(InMemoryDataset):\n",
    "        \n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # List of the raw files\n",
    "        \n",
    "        available_design = [i for i in range(DataSetSize)]\n",
    "        for design_id in available_design:\n",
    "            file_1  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_device_nodes.csv' for i in available_design]\n",
    "            file_2  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net_nodes.csv' for i in available_design]\n",
    "            file_3  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_gate2net_edges.csv' for i in available_design]\n",
    "            file_4  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_source2net_edges.csv' for i in available_design]\n",
    "            file_5  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_capres2net_edges.csv' for i in available_design]\n",
    "            file_6  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_res2net_edges.csv' for i in available_design]\n",
    "            file_7  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2net_edges.csv' for i in available_design]\n",
    "            file_8  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2gate_edges.csv' for i in available_design]\n",
    "            file_9  = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2source_edges.csv' for i in available_design]\n",
    "            file_10 = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2cap_edges.csv' for i in available_design]\n",
    "            file_11 = [DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2res_edges.csv' for i in available_design]\n",
    "        \n",
    "            return file_1 + file_2 + file_3 + file_4 + file_5 + file_6 + file_7 + file_8 + file_9 + file_10 + file_11\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" return list of files should be in processed dir, if found - skip processing.\"\"\"\n",
    "        return ['ALIGN.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        \n",
    "        available_design = [i for i in range(DataSetSize)]\n",
    "        data_list = []\n",
    "   \n",
    "        device_features_mean = np.array([8.2884856e+07, 9.5396346e+08, 7.7310615e+03, 5.4090312e+03, 9.1711110e-01], dtype=np.float32)\n",
    "        device_features_std  = np.array([2.9770163e+08, 1.8716833e+09, 7.4117515e+03, 9.5033213e+03, 1.2663405e+00], dtype=np.float32)\n",
    "        \n",
    "        net_features_mean = np.array([6.4924854e-01, 1.0543352e-01, 4.0369943e-01, 3.4751446e+00, 3.9471447e+01], dtype=np.float32)\n",
    "        net_features_std  = np.array([9.3648350e-01, 3.0710986e-01, 4.9063596e-01, 3.5836630e+00, 3.1141081e+01], dtype=np.float32)\n",
    "\n",
    "        ground_truth_mean = np.array([3.0973297e+04], dtype=np.float32)\n",
    "        ground_truth_std  = np.array([4.0331391e+04], dtype=np.float32)\n",
    "        \n",
    "        prev_device_node_features = torch.Tensor()\n",
    "        prev_net_node_features = torch.Tensor()\n",
    "        \n",
    "        for design_id in available_design:\n",
    "            \n",
    "            if design_id in Extreme_Case:\n",
    "                continue\n",
    "            \n",
    "            data = HeteroData()\n",
    "            \n",
    "            # Device Nodes\n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_device_nodes.csv'\n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                headers = next(rows)\n",
    "                device_node_features_data = np.asarray(list(rows), dtype=np.float32)\n",
    "                device_node_features_data = np.delete(device_node_features_data, 0, 1)\n",
    "                \n",
    "                device_node_features_data = np.divide(np.subtract(device_node_features_data, device_features_mean), device_features_std)\n",
    "                device_node_features = torch.from_numpy(device_node_features_data)\n",
    "                data['device'].x = device_node_features\n",
    "        \n",
    "            # Net Nodes\n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net_nodes.csv'\n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                headers = next(rows)\n",
    "                net_node_features_data = np.asarray(list(rows), dtype=np.float32)\n",
    "                net_node_features_data = np.delete(net_node_features_data, 0, 1)\n",
    "                \n",
    "                net_node_features = torch.from_numpy(net_node_features_data[:,:-1])\n",
    "                ground_truth = torch.from_numpy(net_node_features_data[:,-1])\n",
    "                #ground_truth = torch.from_numpy(np.exp(net_node_features_data[:,-1]))\n",
    "                \n",
    "                data['net'].y = torch.log(ground_truth)\n",
    "                data['net'].train_mask = torch.where(net_node_features[:,1] == 0, True, False)\n",
    "                data['net'].smallnet_mask = torch.logical_and(torch.where(ground_truth <= LargeNetThreshold, True, False), data['net'].train_mask)\n",
    "                data['net'].largenet_mask = torch.logical_and(torch.where(ground_truth >= LargeNetThreshold, True, False), data['net'].train_mask)\n",
    "                \n",
    "                net_node_features_data[:,:-1] = np.divide(np.subtract(net_node_features_data[:,:-1], net_features_mean), net_features_std)\n",
    "                net_node_features = torch.from_numpy(net_node_features_data[:,:-1])\n",
    "                data['net'].x = net_node_features\n",
    "                \n",
    "                \n",
    "             \n",
    "            # Gate to Net Edges Index\n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_gate2net_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                gate2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                gate2net_edge_index_data = torch.from_numpy(gate2net_edge_index_data)\n",
    "                gate2net_edge_index_data = gate2net_edge_index_data.to(torch.long)\n",
    "                N = gate2net_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['device', 'gate2net', 'net'].edge_index = gate2net_edge_index_data\n",
    "                else:\n",
    "                    data['device', 'gate2net', 'net'].edge_index = torch.transpose(gate2net_edge_index_data, 0, 1)\n",
    "     \n",
    "    \n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2gate_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                net2gate_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                net2gate_edge_index_data = torch.from_numpy(net2gate_edge_index_data)\n",
    "                net2gate_edge_index_data = net2gate_edge_index_data.to(torch.long)\n",
    "                N = net2gate_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['net', 'net2gate', 'device'].edge_index = net2gate_edge_index_data\n",
    "                else:\n",
    "                    data['net', 'net2gate', 'device'].edge_index = torch.transpose(net2gate_edge_index_data, 0, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "            # Source to Net Edge Index\n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_source2net_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                source2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                source2net_edge_index_data = torch.from_numpy(source2net_edge_index_data)\n",
    "                source2net_edge_index_data = source2net_edge_index_data.to(torch.long)\n",
    "                N = source2net_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['device', 'source2net', 'net'].edge_index = source2net_edge_index_data\n",
    "                else:\n",
    "                    data['device', 'source2net', 'net'].edge_index = torch.transpose(source2net_edge_index_data, 0, 1)\n",
    "     \n",
    "    \n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2source_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                net2source_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                net2source_edge_index_data = torch.from_numpy(net2source_edge_index_data)\n",
    "                net2source_edge_index_data = net2source_edge_index_data.to(torch.long)\n",
    "                N = net2source_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['net', 'net2source', 'device'].edge_index = net2source_edge_index_data\n",
    "                else:\n",
    "                    data['net', 'net2source', 'device'].edge_index = torch.transpose(net2source_edge_index_data, 0, 1)\n",
    "        \n",
    "        \n",
    "            # Capacitor to Net Edge Index\n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_cap2net_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                cap2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                cap2net_edge_index_data = torch.from_numpy(cap2net_edge_index_data)\n",
    "                cap2net_edge_index_data = cap2net_edge_index_data.to(torch.long)\n",
    "                N = cap2net_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['device', 'cap2net', 'net'].edge_index = cap2net_edge_index_data\n",
    "                else:\n",
    "                    data['device', 'cap2net', 'net'].edge_index = torch.transpose(cap2net_edge_index_data, 0, 1)\n",
    "     \n",
    "    \n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2cap_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                net2cap_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                net2cap_edge_index_data = torch.from_numpy(net2cap_edge_index_data)\n",
    "                net2cap_edge_index_data = net2cap_edge_index_data.to(torch.long)\n",
    "                N = net2cap_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['net', 'net2cap', 'device'].edge_index = net2cap_edge_index_data\n",
    "                else:\n",
    "                    data['net', 'net2cap', 'device'].edge_index = torch.transpose(net2cap_edge_index_data, 0, 1)   \n",
    "      \n",
    "    \n",
    "            # Resistor to Net Edge Index\n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_res2net_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                res2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                res2net_edge_index_data = torch.from_numpy(res2net_edge_index_data)\n",
    "                res2net_edge_index_data = res2net_edge_index_data.to(torch.long)\n",
    "                N = res2net_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['device', 'res2net', 'net'].edge_index = res2net_edge_index_data\n",
    "                else:\n",
    "                    data['device', 'res2net', 'net'].edge_index = torch.transpose(res2net_edge_index_data, 0, 1)\n",
    "     \n",
    "    \n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2res_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                net2res_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                net2res_edge_index_data = torch.from_numpy(net2res_edge_index_data)\n",
    "                net2res_edge_index_data = net2res_edge_index_data.to(torch.long)\n",
    "                N = net2res_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['net', 'net2res', 'device'].edge_index = net2res_edge_index_data\n",
    "                else:\n",
    "                    data['net', 'net2res', 'device'].edge_index = torch.transpose(net2res_edge_index_data, 0, 1)           \n",
    "            \n",
    "            \n",
    "            # Net to Net Edge Index\n",
    "            path = DataSetPath + 'graph' + str(design_id) + '/graph' + str(design_id) + '_net2net_edges.csv'   \n",
    "            with open(path, newline='') as csvfile:\n",
    "                rows = csv.reader(csvfile, delimiter=',')\n",
    "                #next(rows)\n",
    "                net2net_edge_index_data = np.asarray(list(rows), dtype=np.float32)\n",
    "\n",
    "                net2net_edge_index_data = torch.from_numpy(net2net_edge_index_data)\n",
    "                net2net_edge_index_data = net2net_edge_index_data.to(torch.long)\n",
    "                N = net2net_edge_index_data.shape[0]\n",
    "                if N == 0:\n",
    "                    data['net', 'net2net', 'net'].edge_index = net2net_edge_index_data\n",
    "                else:\n",
    "                    data['net', 'net2net', 'net'].edge_index = torch.transpose(net2net_edge_index_data, 0, 1)\n",
    "\n",
    "            if(not torch.equal(device_node_features, prev_device_node_features)):\n",
    "                data_list.append(data)\n",
    "            prev_device_node_features = device_node_features\n",
    "        \n",
    "              \n",
    "        # Apply the functions specified in pre_filter and pre_transform\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "        \n",
    "        #print(data_list)\n",
    "        random.seed(0)\n",
    "        random.shuffle(data_list)\n",
    "        \n",
    "        # Store the processed data\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a3f6cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = ALIGN(root='data_Log_Case_Threshold_20000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ecdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22fe29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a122d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tutorial14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GNN_PyG",
   "language": "python",
   "name": "gnn_pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
